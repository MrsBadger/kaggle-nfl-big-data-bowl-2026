{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# A bir cheat to allow imports from the project root\n",
    "project_root = str(Path.cwd().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39108d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from project.utils.utils import FeatureEngineer, ReverseTransformer, SequentialPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2e674",
   "metadata": {},
   "source": [
    "## Example of working with the FeatureEngineer class\n",
    "\n",
    "#### The class code is located in project.utils.utils, where all the methods are described in detail.\n",
    "#### They replicate the feature engineering logic from uliana_original.ipynb, but you can run them selectively.\n",
    "#### Cache logic has been added to each step to quickly restore results if needed. By default, all methods are set to force_recompute=False to avoid unnecessary recalculation of data. The data will be retrieved from the cache, which is retained after the first run. If you want to recalculate the results, set the force_recompute to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9704376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FeatureEngineer\n",
    "fe = FeatureEngineer(data_path=\"../train\", cache_dir=\"../cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d126c37",
   "metadata": {},
   "source": [
    "### You can run each of these steps individually if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5206ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (mandatory first step)\n",
    "fe.load_data(force_recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.create_training_rows(force_recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.normalize_play_direction(force_recompute=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92875f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.add_kinematic_features(force_recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.add_spatial_features(force_recompute=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a371a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.add_player_features(force_recompute=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd355061",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.add_team_context_features(force_recompute=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f8601",
   "metadata": {},
   "source": [
    "### Or simply run the sequence of steps you need\n",
    "#### **IMPORTANT**: you can skip some steps in the features in the steps_to_run (except for loading data, of course), but I STRONGLY RECOMMEND not to change the order of these steps, as the code does not support this and there may be errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_run = [\n",
    "    \"load_data\",\n",
    "    \"create_training_rows\",\n",
    "    \"normalize_play_direction\",\n",
    "    \"add_kinematic_features\",\n",
    "    \"add_spatial_features\",\n",
    "    \"add_player_features\",\n",
    "    \"add_team_context_features\",\n",
    "    \"add_nearest_defender_distance\",\n",
    "]\n",
    "\n",
    "final_df = fe.get_final_data(steps=steps_to_run, force_recompute=True)\n",
    "feature_cols = fe.get_feature_cols(exclude_cols=['nearest_defender_dist', 'def_mean_dist_to_ball']) # here you can exclude some columns from features if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba546b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cd80b",
   "metadata": {},
   "source": [
    "## Example of working with the FeatureEngineer class to prepare sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0300994",
   "metadata": {},
   "source": [
    "### Prepare sequential data with a fixed number of input and output timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq, y_seq = fe.prepare_sequential_data(n_timesteps_in=5, n_timesteps_out=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ae188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq[:5], y_seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13d2a4",
   "metadata": {},
   "source": [
    "### Prepare sequential data with dynamic output timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_dynamic, y_seq_dynamic = fe.prepare_sequential_data_dynamic(n_timesteps_in=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3924b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_in, seq_out in zip(X_seq_dynamic[:5], y_seq_dynamic[:5]):\n",
    "    print(f\"Input sequence length: {len(seq_in)}\")\n",
    "    print(f\"Output sequence length: {len(seq_out)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0b939",
   "metadata": {},
   "source": [
    "### If you need to force all sequences to a fixed length (for example, for batch training), you can use pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding for input sequences (fixed length n_timesteps_in)\n",
    "X_padded = pad_sequences(X_seq_dynamic, dtype=\"float32\", padding=\"post\")\n",
    "\n",
    "# Padding for output sequences (fixed maximum length)\n",
    "max_out_len = max(len(seq) // 2 for seq in y_seq_dynamic)  # Length in pairs (x, y)\n",
    "y_padded = np.array([\n",
    "    np.pad(seq, (0, max_out_len * 2 - len(seq)), mode=\"constant\")\n",
    "    for seq in y_seq\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1289850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_in, seq_out in zip(X_padded[:5], y_padded[:5]):\n",
    "    print(f\"Padded input sequence length: {len(seq_in)}\")\n",
    "    print(f\"Padded output sequence length: {len(seq_out)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cabf33",
   "metadata": {},
   "source": [
    "## Example of training a model on sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb302249",
   "metadata": {},
   "source": [
    "### MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab692718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_dynamic, y_seq_dynamic = fe.prepare_sequential_data_dynamic(n_timesteps_in=5)\n",
    "\n",
    "# Take a small sample for demonstration\n",
    "X_small = X_seq_dynamic[:100]\n",
    "y_small = y_seq_dynamic[:100]\n",
    "\n",
    "# Padding for dynamic input sequences\n",
    "y_padded = pad_sequences(y_small, dtype=\"float32\", padding=\"post\")\n",
    "\n",
    "# Convert X to a flat array (for sklearn)\n",
    "X_flat = np.array([seq.flatten() for seq in X_small])\n",
    "y_flat = np.array(y_padded)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_flat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=27))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b862ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_padded = model.predict(X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488121b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "rmse_padded = np.sqrt(mean_squared_error(y_padded, y_pred_padded))\n",
    "print(f\"RMSE with padding: {rmse_padded:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069a664",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "#### This is TOO long, but I'll leave it here anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_seq_dynamic, y_seq_dynamic = fe.prepare_sequential_data_dynamic(n_timesteps_in=5)\n",
    "\n",
    "# # Take a small sample for demonstration\n",
    "# X_lstm = np.array(X_seq_dynamic[:5])\n",
    "# y_small = y_seq_dynamic[:5]\n",
    "\n",
    "# y_lstm = pad_sequences(y_small, dtype=\"float32\", padding=\"post\")\n",
    "\n",
    "# X_lstm = X_lstm.astype(\"float32\")\n",
    "# y_lstm = y_lstm.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06acf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model (with padding)\n",
    "# model_lstm = Sequential([\n",
    "#     Masking(mask_value=0.0, input_shape=(X_lstm.shape[1], X_lstm.shape[2])),\n",
    "#     LSTM(64, return_sequences=True),\n",
    "#     LSTM(32),\n",
    "#     Dense(y_lstm.shape[1]),\n",
    "# ])\n",
    "# model_lstm.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# model_lstm.fit(X_lstm, y_lstm, epochs=1, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20135cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# y_pred_lstm_padded = model_lstm.predict(X_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d67ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# rmse_lstm_padded = np.sqrt(mean_squared_error(y_lstm, y_pred_lstm_padded))\n",
    "# print(f\"LSTM RMSE with padding: {rmse_lstm_padded:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d667c",
   "metadata": {},
   "source": [
    "## Example of using the ReverseTransformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_transformer = ReverseTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_small)):\n",
    "    true_y = y_small[i]\n",
    "    pred_y_padded = y_pred_padded[i]\n",
    "\n",
    "    # Remove padding from predictions\n",
    "    pred_y = pred_y_padded[:len(true_y)]\n",
    "\n",
    "    # Trim to the minimum even length\n",
    "    min_length = min(len(true_y), len(pred_y))\n",
    "    if min_length % 2 != 0:\n",
    "        min_length -= 1\n",
    "    true_y = true_y[:min_length]\n",
    "    pred_y = pred_y[:min_length]\n",
    "\n",
    "    # Check lengths\n",
    "    x_length = len(pred_y[::2])\n",
    "    y_length = len(pred_y[1::2])\n",
    "\n",
    "    # Create DataFrame with equal length\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"target_x\": pred_y[::2],\n",
    "        \"target_y\": pred_y[1::2],\n",
    "        \"was_left\": [fe.df.iloc[i][\"was_left\"]] * x_length,  # Repeat the was_left value x_length times\n",
    "    })\n",
    "\n",
    "    true_df = pd.DataFrame({\n",
    "        \"target_x\": true_y[::2],\n",
    "        \"target_y\": true_y[1::2],\n",
    "        \"was_left\": [fe.df.iloc[i][\"was_left\"]] * x_length,\n",
    "    })\n",
    "\n",
    "    # Apply inverse transformations\n",
    "    transformed_pred = reverse_transformer.transform(pred_df)\n",
    "    transformed_pred_values = transformed_pred[[\"target_x\", \"target_y\"]].values.flatten()\n",
    "\n",
    "    transformed_true = reverse_transformer.transform(true_df)\n",
    "    transformed_true_values = transformed_true[[\"target_x\", \"target_y\"]].values.flatten()\n",
    "\n",
    "    # RMSE\n",
    "    rmse_transformed = np.sqrt(mean_squared_error(transformed_true_values, transformed_pred_values))\n",
    "    print(f\"Sequence {i+1}: RMSE = {rmse_transformed:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203a527",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
